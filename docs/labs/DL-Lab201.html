
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Laboratory Task 201 &#8212; My JupyterBook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'labs/DL-Lab201';</script>
    <link rel="canonical" href="/culanggo-jb/labs/DL-Lab201.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="When Learning Rates Decay: What Really Happens Inside a CNN" href="Homework201.html" />
    <link rel="prev" title="Laboratory Task 6" href="DL-Lab6.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/kein logo.png" class="logo__image only-light" alt="My JupyterBook - Home"/>
    <script>document.write(`<img src="../_static/kein logo.png" class="logo__image only-dark" alt="My JupyterBook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    About Me
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson1/lesson1.html">Lecture 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson2/lesson2.html">Lecture 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson3/lesson3.html">Lecture 3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson4/lesson4.html">Lecture 4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson5/lesson5.html">Lecture 5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson6/lesson6.html">Lecture 6</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Labs</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DL-Lab1.html"><strong>Laboratory Task 1</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="DL-Lab2.html"><strong>Laboratory Task 2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="DL-Lab3.html"><strong>Laboratory Task 3</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="DL-Lab4.html"><strong>Laboratory Task 4</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="DL-Lab5.html"><strong>Laboratory Task 5</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="DL-Lab6.html"><strong>Laboratory Task 6</strong></a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>Laboratory Task 201</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Homework201.html">Homework 201</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Narrative Reports</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../narrative-reports/phase1.html">Phase 1: Narrative Report - Final Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../narrative-reports/phase2.html">Phase 2: Narrative Report - Final Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../narrative-reports/phase3.html">Phase 3: Narrative Report - Final Project</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/jehiku/culanggo-jb" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/jehiku/culanggo-jb/issues/new?title=Issue%20on%20page%20%2Flabs/DL-Lab201.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/labs/DL-Lab201.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Laboratory Task 201</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kein-jake-a-culanggo">Kein Jake A. Culanggo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ds4a">DS4A</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-source"><strong>Dataset Source:</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-class"><strong>Dataset Class</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-a-sample"><strong>Loading a Sample</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-we-did-it-this-way"><strong>Why We Did It This Way</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformations-getting-images-ready"><strong>Transformations: Getting Images Ready</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-and-splitting-the-dataset"><strong>Loading and Splitting the Dataset</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cnn-definition-flexible-activation-functions"><strong>CNN Definition: Flexible Activation Functions</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-setup-activations-optimizers-and-device"><strong>Experiment Setup: Activations, Optimizers, and Device</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-loop-training-and-tracking-results"><strong>Experiment Loop: Training and Tracking Results</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-takeaways">Key Takeaways</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relu-activation-function">ReLU Activation Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#leakyrelu-activation-function">LeakyReLU Activation Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#elu-activation-function">ELU Activation Function</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion"><strong>Conclusion</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bottomline"><strong>Bottomline:</strong></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="laboratory-task-201">
<h1><strong>Laboratory Task 201</strong><a class="headerlink" href="#laboratory-task-201" title="Link to this heading">#</a></h1>
<section id="kein-jake-a-culanggo">
<h2>Kein Jake A. Culanggo<a class="headerlink" href="#kein-jake-a-culanggo" title="Link to this heading">#</a></h2>
</section>
<section id="ds4a">
<h2>DS4A<a class="headerlink" href="#ds4a" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># libraries</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">cv2</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="dataset-source">
<h2><strong>Dataset Source:</strong><a class="headerlink" href="#dataset-source" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://www.kaggle.com/datasets/farukece/handwritten-japanese-hiragana-characters?resource=download">https://www.kaggle.com/datasets/farukece/handwritten-japanese-hiragana-characters?resource=download</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">root</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;C:\Users\Kein Jake\Downloads\hiragana\hiragana&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dataset Definition</span>
<span class="k">class</span><span class="w"> </span><span class="nc">HiraganaDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">transforms</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_paths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>

        <span class="n">subfolders</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">root</span><span class="p">))</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">f</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">subfolder</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">subfolder</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">subfolders</span><span class="p">)}</span>

        <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">subfolder</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">subfolders</span><span class="p">):</span>
            <span class="n">subfolder_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">subfolder</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">img_name</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">subfolder_path</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">img_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">endswith</span><span class="p">((</span><span class="s1">&#39;.png&#39;</span><span class="p">,</span> <span class="s1">&#39;.jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;.jpeg&#39;</span><span class="p">)):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">image_paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">subfolder_path</span><span class="p">,</span> <span class="n">img_name</span><span class="p">))</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">img_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_paths</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
        <span class="n">label_name</span> <span class="o">=</span> <span class="n">img_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">sep</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_map</span><span class="p">[</span><span class="n">label_name</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">label</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_paths</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="dataset-class">
<h3><strong>Dataset Class</strong><a class="headerlink" href="#dataset-class" title="Link to this heading">#</a></h3>
<p>Okay, so think of the HiraganaDataset class as our way of teaching PyTorch how to grab the images and labels. We point it to the main folder, and it looks inside each subfolder. Each subfolder is a different Hiragana character. It collects all the image paths and gives each folder a number. That number is what the model will see as the label. When the model gets fed a batch of images, it knows which class each one belongs to.</p>
</section>
<section id="loading-a-sample">
<h3><strong>Loading a Sample</strong><a class="headerlink" href="#loading-a-sample" title="Link to this heading">#</a></h3>
<p>When we grab one image with <strong>getitem</strong>, the class opens the image and converts it to RGB. We do this so the CNN does not get confused with channels. Then it looks at the folder name to figure out the label and applies any preprocessing we set up, like resizing, random rotation, or normalization. The cool thing is that all this happens on the fly, so we do not have to manually preprocess all 10,000 images before training. This saves memory and time.</p>
</section>
<section id="why-we-did-it-this-way">
<h3><strong>Why We Did It This Way</strong><a class="headerlink" href="#why-we-did-it-this-way" title="Link to this heading">#</a></h3>
<p>This approach is flexible and neat. Using a custom dataset means we can swap datasets, tweak transforms, or filter classes easily without rewriting code. It also works perfectly with PyTorchâ€™s DataLoader, so batching, shuffling, and parallel loading all just work. It keeps everything organized, clean, and ready for experiments without a bunch of manual work.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Transformations</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Grayscale</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">56</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mi">15</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">])</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="transformations-getting-images-ready">
<h3><strong>Transformations: Getting Images Ready</strong><a class="headerlink" href="#transformations-getting-images-ready" title="Link to this heading">#</a></h3>
<p>Here we define how to preprocess the images before sending them into the model. We convert them to grayscale and resize to a fixed size so everything is uniform. The random resized crop and slight rotations add variability, which helps the model handle small shifts in the characters. We also apply a tiny chance of horizontal flipping. Finally, we turn the images into tensors and normalize them so training is smoother. These steps are mostly about consistency and giving the model a little extra robustness without overcomplicating things.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load Dataset and Split</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">HiraganaDataset</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">root</span><span class="p">,</span> <span class="n">transforms</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="n">total</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">val_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.1</span> <span class="o">*</span> <span class="n">total</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">total</span> <span class="o">-</span> <span class="n">train_size</span> <span class="o">-</span> <span class="n">val_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">val_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">val_size</span><span class="p">,</span> <span class="n">test_size</span><span class="p">],</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="loading-and-splitting-the-dataset">
<h3><strong>Loading and Splitting the Dataset</strong><a class="headerlink" href="#loading-and-splitting-the-dataset" title="Link to this heading">#</a></h3>
<p>Once the dataset is ready, we create an instance of HiraganaDataset with our transforms. We calculate the total number of images and split them into training, validation, and test sets with roughly 80, 10, and 10 percent of the data. Using a fixed random seed ensures the split is reproducible. Then we wrap each subset in a DataLoader to handle batching and shuffling. Training batches are shuffled to avoid any order bias, while validation and test batches are not shuffled because we want consistent evaluation. This setup gives us a clean pipeline for feeding images into the model and evaluating performance reliably.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># List all classes as strings</span>
<span class="n">class_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">class_map</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Classes in the dataset:&quot;</span><span class="p">,</span> <span class="n">class_list</span><span class="p">)</span>

<span class="c1"># Pick one sample per class</span>
<span class="n">samples_per_class</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">img_path</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">image_paths</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">samples_per_class</span><span class="p">:</span>
        <span class="n">samples_per_class</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">img_path</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples_per_class</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">class_map</span><span class="p">):</span>
        <span class="k">break</span>

<span class="c1"># Plot samples</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">class_map</span><span class="p">)</span>
<span class="n">cols</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_classes</span> <span class="o">/</span> <span class="n">cols</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">cols</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">rows</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Sample Images per Hiragana Class (Plasma Colormap)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">img_path</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">samples_per_class</span><span class="o">.</span><span class="n">items</span><span class="p">())):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;L&quot;</span><span class="p">)</span>  <span class="c1"># grayscale</span>
    <span class="n">img_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img_np</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;plasma&#39;</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">class_list</span><span class="p">[</span><span class="n">label</span><span class="p">]</span><span class="o">.</span><span class="n">upper</span><span class="p">(),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  <span class="c1"># label is int index</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Classes in the dataset: [&#39;aa&#39;, &#39;chi&#39;, &#39;ee&#39;, &#39;fu&#39;, &#39;ha&#39;, &#39;he&#39;, &#39;hi&#39;, &#39;ho&#39;, &#39;ii&#39;, &#39;ka&#39;, &#39;ke&#39;, &#39;ki&#39;, &#39;ko&#39;, &#39;ku&#39;, &#39;ma&#39;, &#39;me&#39;, &#39;mi&#39;, &#39;mo&#39;, &#39;mu&#39;, &#39;na&#39;, &#39;ne&#39;, &#39;ni&#39;, &#39;nn&#39;, &#39;no&#39;, &#39;nu&#39;, &#39;oo&#39;, &#39;ra&#39;, &#39;re&#39;, &#39;ri&#39;, &#39;ro&#39;, &#39;ru&#39;, &#39;sa&#39;, &#39;se&#39;, &#39;shi&#39;, &#39;so&#39;, &#39;su&#39;, &#39;ta&#39;, &#39;te&#39;, &#39;to&#39;, &#39;tsu&#39;, &#39;uu&#39;, &#39;wa&#39;, &#39;wo&#39;, &#39;ya&#39;, &#39;yo&#39;, &#39;yu&#39;]
</pre></div>
</div>
<img alt="../_images/700039782b5379ec8c6ea632502556c841a165856fb83e324eac631d7f116205.png" src="../_images/700039782b5379ec8c6ea632502556c841a165856fb83e324eac631d7f116205.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># CNN Definition (Activation function as parameter)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">HiraganaCNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">63</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">HiraganaCNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">activation_fn</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>

            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">activation_fn</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>

            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">activation_fn</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="o">*</span><span class="mi">7</span><span class="o">*</span><span class="mi">7</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">activation_fn</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cnn-definition-flexible-activation-functions">
<h3><strong>CNN Definition: Flexible Activation Functions</strong><a class="headerlink" href="#cnn-definition-flexible-activation-functions" title="Link to this heading">#</a></h3>
<p>This is our core model, HiraganaCNN. Itâ€™s a fairly standard CNN, but we made it flexible by letting the activation function be a parameter. That way, we can easily swap ReLU, LeakyReLU, ELU, or others without changing the rest of the architecture. The feature extractor has three convolutional layers, each followed by the chosen activation, batch normalization, and max pooling to reduce spatial dimensions. After the convolutional blocks, we flatten the features and pass them through a small fully connected classifier with one hidden layer, the same activation, and dropout for regularization. The last layer outputs raw logits for each class, which works perfectly with CrossEntropyLoss during training. This setup keeps the architecture consistent while allowing us to experiment with different activation functions to see how they affect training and performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Experiment Setup</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="n">activation_functions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;ReLU&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="s1">&#39;LeakyReLU&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">,</span>
    <span class="s1">&#39;ELU&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span>
<span class="p">}</span>

<span class="n">optimizers_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Adam&#39;</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
    <span class="s1">&#39;SGD&#39;</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span>
    <span class="s1">&#39;RMSprop&#39;</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span>
<span class="p">}</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0007</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="experiment-setup-activations-optimizers-and-device">
<h3><strong>Experiment Setup: Activations, Optimizers, and Device</strong><a class="headerlink" href="#experiment-setup-activations-optimizers-and-device" title="Link to this heading">#</a></h3>
<p>Here we set up the experiment environment. First, we choose whether to run on GPU or CPU. Then we define the activation functions and optimizers we want to test. The idea is to keep the CNN architecture the same and only change the activation function or optimizer in each run to see how they affect performance. We also set the number of epochs and the learning rate so every experiment is comparable. This way, we can fairly evaluate which combination trains fastest, generalizes best, and achieves the highest accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Experiment Loop</span>
<span class="n">experiment_results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">act_name</span><span class="p">,</span> <span class="n">act_fn</span> <span class="ow">in</span> <span class="n">activation_functions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">opt_name</span><span class="p">,</span> <span class="n">opt_fn</span> <span class="ow">in</span> <span class="n">optimizers_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Training with Activation: </span><span class="si">{</span><span class="n">act_name</span><span class="si">}</span><span class="s2">, Optimizer: </span><span class="si">{</span><span class="n">opt_name</span><span class="si">}</span><span class="s2"> ---&quot;</span><span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">HiraganaCNN</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">class_map</span><span class="p">),</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">act_fn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt_fn</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

        <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">train_accs</span><span class="p">,</span> <span class="n">val_accs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">best_val_acc</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">best_epoch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">best_model_state</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">running_loss</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
                <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
            <span class="n">avg_train_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_correct</span><span class="p">,</span> <span class="n">val_total</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                    <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                    <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">val_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="n">val_total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">val_acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">val_correct</span> <span class="o">/</span> <span class="n">val_total</span>
            <span class="n">avg_val_loss</span> <span class="o">=</span> <span class="n">val_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span>

            <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_train_loss</span><span class="p">)</span>
            <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_val_loss</span><span class="p">)</span>
            <span class="n">train_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>
            <span class="n">val_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">val_acc</span> <span class="o">&gt;</span> <span class="n">best_val_acc</span><span class="p">:</span>
                <span class="n">best_val_acc</span> <span class="o">=</span> <span class="n">val_acc</span>
                <span class="n">best_epoch</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="n">best_model_state</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">] &quot;</span>
                  <span class="sa">f</span><span class="s2">&quot;Train Loss: </span><span class="si">{</span><span class="n">avg_train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Train Acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">% | &quot;</span>
                  <span class="sa">f</span><span class="s2">&quot;Val Loss: </span><span class="si">{</span><span class="n">avg_val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Acc: </span><span class="si">{</span><span class="n">val_acc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

        <span class="c1"># Load best model for testing</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_state</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best Epoch: </span><span class="si">{</span><span class="n">best_epoch</span><span class="si">}</span><span class="s2">, Test Accuracy: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

        <span class="c1"># Store results</span>
        <span class="n">experiment_results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;Activation&#39;</span><span class="p">:</span> <span class="n">act_name</span><span class="p">,</span>
            <span class="s1">&#39;Optimizer&#39;</span><span class="p">:</span> <span class="n">opt_name</span><span class="p">,</span>
            <span class="s1">&#39;Best Epoch&#39;</span><span class="p">:</span> <span class="n">best_epoch</span><span class="p">,</span>
            <span class="s1">&#39;Test Accuracy&#39;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">,</span>
            <span class="s1">&#39;Train Loss&#39;</span><span class="p">:</span> <span class="n">train_losses</span><span class="p">,</span>
            <span class="s1">&#39;Val Loss&#39;</span><span class="p">:</span> <span class="n">val_losses</span><span class="p">,</span>
            <span class="s1">&#39;Train Acc&#39;</span><span class="p">:</span> <span class="n">train_accs</span><span class="p">,</span>
            <span class="s1">&#39;Val Acc&#39;</span><span class="p">:</span> <span class="n">val_accs</span>
        <span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Training with Activation: ReLU, Optimizer: Adam ---
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/20] Train Loss: 1.7632, Train Acc: 55.79% | Val Loss: 0.4167, Val Acc: 87.83%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [2/20] Train Loss: 0.3335, Train Acc: 90.57% | Val Loss: 0.1372, Val Acc: 95.87%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [3/20] Train Loss: 0.2098, Train Acc: 93.83% | Val Loss: 0.0562, Val Acc: 98.26%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [4/20] Train Loss: 0.1388, Train Acc: 95.62% | Val Loss: 0.0679, Val Acc: 98.48%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [5/20] Train Loss: 0.0997, Train Acc: 97.07% | Val Loss: 0.0291, Val Acc: 98.91%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [6/20] Train Loss: 0.0726, Train Acc: 97.74% | Val Loss: 0.0236, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [7/20] Train Loss: 0.0773, Train Acc: 97.47% | Val Loss: 0.0163, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [8/20] Train Loss: 0.0587, Train Acc: 98.48% | Val Loss: 0.0378, Val Acc: 98.70%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [9/20] Train Loss: 0.0640, Train Acc: 98.21% | Val Loss: 0.0092, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/20] Train Loss: 0.0435, Train Acc: 98.78% | Val Loss: 0.0059, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [11/20] Train Loss: 0.0379, Train Acc: 98.97% | Val Loss: 0.0200, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [12/20] Train Loss: 0.0352, Train Acc: 98.86% | Val Loss: 0.0298, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [13/20] Train Loss: 0.0417, Train Acc: 98.75% | Val Loss: 0.0195, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [14/20] Train Loss: 0.0468, Train Acc: 98.42% | Val Loss: 0.0412, Val Acc: 98.26%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [15/20] Train Loss: 0.0413, Train Acc: 98.61% | Val Loss: 0.0126, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [16/20] Train Loss: 0.0546, Train Acc: 98.21% | Val Loss: 0.0058, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [17/20] Train Loss: 0.0577, Train Acc: 97.91% | Val Loss: 0.0129, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [18/20] Train Loss: 0.0318, Train Acc: 98.99% | Val Loss: 0.0173, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [19/20] Train Loss: 0.0283, Train Acc: 99.05% | Val Loss: 0.0033, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [20/20] Train Loss: 0.0370, Train Acc: 98.75% | Val Loss: 0.0046, Val Acc: 99.78%
Best Epoch: 9, Test Accuracy: 99.13%

--- Training with Activation: ReLU, Optimizer: SGD ---
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/20] Train Loss: 3.8524, Train Acc: 3.34% | Val Loss: 3.7002, Val Acc: 9.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [2/20] Train Loss: 3.6791, Train Acc: 7.36% | Val Loss: 3.5735, Val Acc: 18.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [3/20] Train Loss: 3.5380, Train Acc: 12.42% | Val Loss: 3.3834, Val Acc: 34.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [4/20] Train Loss: 3.3703, Train Acc: 20.60% | Val Loss: 3.2334, Val Acc: 50.87%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [5/20] Train Loss: 3.1878, Train Acc: 28.56% | Val Loss: 3.0232, Val Acc: 57.17%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [6/20] Train Loss: 2.9941, Train Acc: 37.69% | Val Loss: 2.7969, Val Acc: 66.96%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [7/20] Train Loss: 2.7777, Train Acc: 44.46% | Val Loss: 2.5560, Val Acc: 75.65%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [8/20] Train Loss: 2.5646, Train Acc: 50.84% | Val Loss: 2.3235, Val Acc: 77.61%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [9/20] Train Loss: 2.3590, Train Acc: 55.65% | Val Loss: 2.0841, Val Acc: 82.61%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/20] Train Loss: 2.1542, Train Acc: 61.82% | Val Loss: 1.8695, Val Acc: 84.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [11/20] Train Loss: 1.9639, Train Acc: 64.78% | Val Loss: 1.6887, Val Acc: 87.61%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [12/20] Train Loss: 1.7843, Train Acc: 69.54% | Val Loss: 1.5460, Val Acc: 87.39%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [13/20] Train Loss: 1.6246, Train Acc: 71.58% | Val Loss: 1.3457, Val Acc: 88.91%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [14/20] Train Loss: 1.4626, Train Acc: 74.76% | Val Loss: 1.2365, Val Acc: 90.00%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [15/20] Train Loss: 1.3495, Train Acc: 75.27% | Val Loss: 1.0755, Val Acc: 88.91%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [16/20] Train Loss: 1.2273, Train Acc: 77.66% | Val Loss: 0.9871, Val Acc: 89.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [17/20] Train Loss: 1.1295, Train Acc: 80.11% | Val Loss: 0.9084, Val Acc: 89.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [18/20] Train Loss: 1.0429, Train Acc: 81.44% | Val Loss: 0.8650, Val Acc: 90.65%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [19/20] Train Loss: 0.9496, Train Acc: 82.61% | Val Loss: 0.7616, Val Acc: 90.65%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [20/20] Train Loss: 0.9401, Train Acc: 81.96% | Val Loss: 0.6636, Val Acc: 93.91%
Best Epoch: 20, Test Accuracy: 89.78%

--- Training with Activation: ReLU, Optimizer: RMSprop ---
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/20] Train Loss: 3.7615, Train Acc: 35.92% | Val Loss: 0.9260, Val Acc: 76.52%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [2/20] Train Loss: 0.7984, Train Acc: 77.31% | Val Loss: 0.3060, Val Acc: 92.39%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [3/20] Train Loss: 0.4424, Train Acc: 87.04% | Val Loss: 0.1920, Val Acc: 95.87%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [4/20] Train Loss: 0.2960, Train Acc: 91.11% | Val Loss: 0.1021, Val Acc: 97.61%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [5/20] Train Loss: 0.2246, Train Acc: 93.40% | Val Loss: 0.0406, Val Acc: 98.70%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [6/20] Train Loss: 0.1796, Train Acc: 94.86% | Val Loss: 0.0643, Val Acc: 98.70%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [7/20] Train Loss: 0.1415, Train Acc: 95.30% | Val Loss: 0.0394, Val Acc: 98.70%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [8/20] Train Loss: 0.1152, Train Acc: 96.68% | Val Loss: 0.0333, Val Acc: 98.70%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [9/20] Train Loss: 0.1266, Train Acc: 95.90% | Val Loss: 0.0309, Val Acc: 98.48%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/20] Train Loss: 0.1154, Train Acc: 96.52% | Val Loss: 0.0271, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [11/20] Train Loss: 0.0869, Train Acc: 96.93% | Val Loss: 0.0135, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [12/20] Train Loss: 0.0853, Train Acc: 97.64% | Val Loss: 0.0226, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [13/20] Train Loss: 0.0732, Train Acc: 97.93% | Val Loss: 1.8305, Val Acc: 76.74%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [14/20] Train Loss: 0.0618, Train Acc: 98.02% | Val Loss: 0.0133, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [15/20] Train Loss: 0.0809, Train Acc: 97.20% | Val Loss: 0.0035, Val Acc: 100.00%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [16/20] Train Loss: 0.0499, Train Acc: 98.32% | Val Loss: 0.0069, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [17/20] Train Loss: 0.0634, Train Acc: 98.02% | Val Loss: 0.0204, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [18/20] Train Loss: 0.0645, Train Acc: 98.07% | Val Loss: 0.0165, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [19/20] Train Loss: 0.0644, Train Acc: 98.37% | Val Loss: 0.0245, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [20/20] Train Loss: 0.0691, Train Acc: 98.02% | Val Loss: 0.0183, Val Acc: 99.78%
Best Epoch: 15, Test Accuracy: 99.78%

--- Training with Activation: LeakyReLU, Optimizer: Adam ---
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/20] Train Loss: 1.7697, Train Acc: 56.58% | Val Loss: 0.4279, Val Acc: 90.65%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [2/20] Train Loss: 0.3262, Train Acc: 91.09% | Val Loss: 0.1229, Val Acc: 96.74%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [3/20] Train Loss: 0.1620, Train Acc: 95.00% | Val Loss: 0.0789, Val Acc: 98.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [4/20] Train Loss: 0.1038, Train Acc: 96.88% | Val Loss: 0.0355, Val Acc: 98.91%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [5/20] Train Loss: 0.0799, Train Acc: 97.55% | Val Loss: 0.0447, Val Acc: 98.70%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [6/20] Train Loss: 0.0798, Train Acc: 97.80% | Val Loss: 0.0352, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [7/20] Train Loss: 0.0615, Train Acc: 98.18% | Val Loss: 0.0239, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [8/20] Train Loss: 0.0789, Train Acc: 97.53% | Val Loss: 0.0095, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [9/20] Train Loss: 0.0659, Train Acc: 98.04% | Val Loss: 0.0109, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/20] Train Loss: 0.0586, Train Acc: 98.34% | Val Loss: 0.0057, Val Acc: 100.00%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [11/20] Train Loss: 0.0431, Train Acc: 98.78% | Val Loss: 0.0066, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [12/20] Train Loss: 0.0324, Train Acc: 98.91% | Val Loss: 0.0188, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [13/20] Train Loss: 0.0408, Train Acc: 98.75% | Val Loss: 0.0120, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [14/20] Train Loss: 0.0355, Train Acc: 98.91% | Val Loss: 0.0072, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [15/20] Train Loss: 0.0293, Train Acc: 99.10% | Val Loss: 0.0021, Val Acc: 100.00%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [16/20] Train Loss: 0.0553, Train Acc: 98.34% | Val Loss: 0.0165, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [17/20] Train Loss: 0.0464, Train Acc: 98.64% | Val Loss: 0.0075, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [18/20] Train Loss: 0.0341, Train Acc: 98.91% | Val Loss: 0.0170, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [19/20] Train Loss: 0.0228, Train Acc: 99.21% | Val Loss: 0.0016, Val Acc: 100.00%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [20/20] Train Loss: 0.0267, Train Acc: 99.10% | Val Loss: 0.0210, Val Acc: 99.35%
Best Epoch: 10, Test Accuracy: 99.57%

--- Training with Activation: LeakyReLU, Optimizer: SGD ---
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/20] Train Loss: 3.8427, Train Acc: 3.51% | Val Loss: 3.6947, Val Acc: 5.87%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [2/20] Train Loss: 3.6835, Train Acc: 7.55% | Val Loss: 3.5623, Val Acc: 21.30%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [3/20] Train Loss: 3.5239, Train Acc: 13.45% | Val Loss: 3.3824, Val Acc: 39.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [4/20] Train Loss: 3.3568, Train Acc: 20.87% | Val Loss: 3.2200, Val Acc: 48.48%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [5/20] Train Loss: 3.1780, Train Acc: 29.92% | Val Loss: 2.9948, Val Acc: 62.17%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [6/20] Train Loss: 2.9684, Train Acc: 37.83% | Val Loss: 2.7692, Val Acc: 69.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [7/20] Train Loss: 2.7524, Train Acc: 45.76% | Val Loss: 2.5459, Val Acc: 74.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [8/20] Train Loss: 2.5351, Train Acc: 52.77% | Val Loss: 2.3071, Val Acc: 80.87%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [9/20] Train Loss: 2.3285, Train Acc: 57.50% | Val Loss: 2.1008, Val Acc: 81.09%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/20] Train Loss: 2.1433, Train Acc: 61.68% | Val Loss: 1.8260, Val Acc: 86.30%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [11/20] Train Loss: 1.9199, Train Acc: 66.11% | Val Loss: 1.6581, Val Acc: 85.22%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [12/20] Train Loss: 1.7505, Train Acc: 68.89% | Val Loss: 1.4876, Val Acc: 87.61%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [13/20] Train Loss: 1.6245, Train Acc: 70.30% | Val Loss: 1.3349, Val Acc: 88.48%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [14/20] Train Loss: 1.4539, Train Acc: 74.84% | Val Loss: 1.1025, Val Acc: 90.87%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [15/20] Train Loss: 1.3249, Train Acc: 76.96% | Val Loss: 1.0524, Val Acc: 91.30%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [16/20] Train Loss: 1.2314, Train Acc: 78.67% | Val Loss: 0.9565, Val Acc: 92.17%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [17/20] Train Loss: 1.1119, Train Acc: 79.84% | Val Loss: 0.8646, Val Acc: 91.96%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [18/20] Train Loss: 1.0648, Train Acc: 81.01% | Val Loss: 0.7875, Val Acc: 90.65%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [19/20] Train Loss: 0.9870, Train Acc: 82.26% | Val Loss: 0.7692, Val Acc: 92.61%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [20/20] Train Loss: 0.9270, Train Acc: 82.66% | Val Loss: 0.7205, Val Acc: 91.30%
Best Epoch: 19, Test Accuracy: 89.57%

--- Training with Activation: LeakyReLU, Optimizer: RMSprop ---
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/20] Train Loss: 2.9318, Train Acc: 48.10% | Val Loss: 0.5673, Val Acc: 86.09%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [2/20] Train Loss: 0.5500, Train Acc: 84.29% | Val Loss: 0.1109, Val Acc: 96.52%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [3/20] Train Loss: 0.2744, Train Acc: 92.01% | Val Loss: 0.0775, Val Acc: 97.39%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [4/20] Train Loss: 0.1728, Train Acc: 94.76% | Val Loss: 0.1176, Val Acc: 97.39%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [5/20] Train Loss: 0.1296, Train Acc: 96.09% | Val Loss: 0.0465, Val Acc: 98.48%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [6/20] Train Loss: 0.1168, Train Acc: 96.33% | Val Loss: 0.0407, Val Acc: 98.26%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [7/20] Train Loss: 0.0858, Train Acc: 97.45% | Val Loss: 0.0235, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [8/20] Train Loss: 0.0911, Train Acc: 97.39% | Val Loss: 0.0392, Val Acc: 98.26%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [9/20] Train Loss: 0.0852, Train Acc: 97.34% | Val Loss: 0.0140, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/20] Train Loss: 0.0865, Train Acc: 97.34% | Val Loss: 0.0101, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [11/20] Train Loss: 0.0611, Train Acc: 98.07% | Val Loss: 0.0098, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [12/20] Train Loss: 0.0502, Train Acc: 98.45% | Val Loss: 0.0316, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [13/20] Train Loss: 0.0500, Train Acc: 98.21% | Val Loss: 0.0266, Val Acc: 98.91%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [14/20] Train Loss: 0.0742, Train Acc: 97.83% | Val Loss: 0.0729, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [15/20] Train Loss: 0.0487, Train Acc: 98.45% | Val Loss: 0.0727, Val Acc: 97.83%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [16/20] Train Loss: 0.0492, Train Acc: 98.51% | Val Loss: 0.0026, Val Acc: 100.00%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [17/20] Train Loss: 0.0436, Train Acc: 98.80% | Val Loss: 0.0072, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [18/20] Train Loss: 0.0508, Train Acc: 98.75% | Val Loss: 0.0240, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [19/20] Train Loss: 0.0391, Train Acc: 98.83% | Val Loss: 0.0474, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [20/20] Train Loss: 0.0453, Train Acc: 98.86% | Val Loss: 0.0260, Val Acc: 99.13%
Best Epoch: 16, Test Accuracy: 99.35%

--- Training with Activation: ELU, Optimizer: Adam ---
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/20] Train Loss: 2.0360, Train Acc: 49.57% | Val Loss: 0.3395, Val Acc: 92.61%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [2/20] Train Loss: 0.4230, Train Acc: 87.69% | Val Loss: 0.2322, Val Acc: 95.65%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [3/20] Train Loss: 0.2370, Train Acc: 93.10% | Val Loss: 0.2363, Val Acc: 94.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [4/20] Train Loss: 0.1528, Train Acc: 95.35% | Val Loss: 0.1193, Val Acc: 97.83%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [5/20] Train Loss: 0.1163, Train Acc: 96.30% | Val Loss: 0.0371, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [6/20] Train Loss: 0.0920, Train Acc: 97.42% | Val Loss: 0.0339, Val Acc: 98.91%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [7/20] Train Loss: 0.0779, Train Acc: 97.72% | Val Loss: 0.0173, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [8/20] Train Loss: 0.0545, Train Acc: 98.15% | Val Loss: 0.0126, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [9/20] Train Loss: 0.0542, Train Acc: 98.32% | Val Loss: 0.0211, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/20] Train Loss: 0.0578, Train Acc: 98.26% | Val Loss: 0.0300, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [11/20] Train Loss: 0.0523, Train Acc: 98.48% | Val Loss: 0.0334, Val Acc: 98.91%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [12/20] Train Loss: 0.0413, Train Acc: 98.59% | Val Loss: 0.0420, Val Acc: 98.70%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [13/20] Train Loss: 0.0454, Train Acc: 98.64% | Val Loss: 0.0131, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [14/20] Train Loss: 0.0495, Train Acc: 98.37% | Val Loss: 0.0239, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [15/20] Train Loss: 0.0559, Train Acc: 98.32% | Val Loss: 0.0209, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [16/20] Train Loss: 0.0550, Train Acc: 98.42% | Val Loss: 0.0200, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [17/20] Train Loss: 0.0337, Train Acc: 98.83% | Val Loss: 0.0014, Val Acc: 100.00%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [18/20] Train Loss: 0.0507, Train Acc: 98.45% | Val Loss: 0.0082, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [19/20] Train Loss: 0.0351, Train Acc: 98.97% | Val Loss: 0.0028, Val Acc: 100.00%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [20/20] Train Loss: 0.0444, Train Acc: 98.56% | Val Loss: 0.0145, Val Acc: 99.57%
Best Epoch: 17, Test Accuracy: 98.04%

--- Training with Activation: ELU, Optimizer: SGD ---
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/20] Train Loss: 3.8047, Train Acc: 4.43% | Val Loss: 3.6393, Val Acc: 11.30%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [2/20] Train Loss: 3.6005, Train Acc: 9.43% | Val Loss: 3.4644, Val Acc: 23.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [3/20] Train Loss: 3.3761, Train Acc: 19.78% | Val Loss: 3.2472, Val Acc: 42.39%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [4/20] Train Loss: 3.1784, Train Acc: 31.22% | Val Loss: 2.9896, Val Acc: 60.00%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [5/20] Train Loss: 2.9653, Train Acc: 42.58% | Val Loss: 2.8263, Val Acc: 69.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [6/20] Train Loss: 2.7357, Train Acc: 52.55% | Val Loss: 2.6035, Val Acc: 75.65%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [7/20] Train Loss: 2.5198, Train Acc: 59.40% | Val Loss: 2.3541, Val Acc: 77.17%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [8/20] Train Loss: 2.3298, Train Acc: 64.46% | Val Loss: 2.1940, Val Acc: 78.91%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [9/20] Train Loss: 2.1456, Train Acc: 68.18% | Val Loss: 1.9831, Val Acc: 86.30%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/20] Train Loss: 1.9768, Train Acc: 70.79% | Val Loss: 1.7835, Val Acc: 85.22%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [11/20] Train Loss: 1.8087, Train Acc: 73.99% | Val Loss: 1.6454, Val Acc: 86.52%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [12/20] Train Loss: 1.6747, Train Acc: 75.90% | Val Loss: 1.4855, Val Acc: 86.52%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [13/20] Train Loss: 1.5505, Train Acc: 78.04% | Val Loss: 1.3870, Val Acc: 86.96%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [14/20] Train Loss: 1.4572, Train Acc: 78.37% | Val Loss: 1.3232, Val Acc: 86.30%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [15/20] Train Loss: 1.3567, Train Acc: 80.00% | Val Loss: 1.2141, Val Acc: 88.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [16/20] Train Loss: 1.2668, Train Acc: 81.58% | Val Loss: 1.0598, Val Acc: 89.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [17/20] Train Loss: 1.1935, Train Acc: 81.90% | Val Loss: 1.0498, Val Acc: 88.91%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [18/20] Train Loss: 1.1110, Train Acc: 83.18% | Val Loss: 0.9811, Val Acc: 90.22%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [19/20] Train Loss: 1.0423, Train Acc: 84.21% | Val Loss: 0.8030, Val Acc: 92.83%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [20/20] Train Loss: 0.9814, Train Acc: 85.00% | Val Loss: 0.8522, Val Acc: 90.00%
Best Epoch: 19, Test Accuracy: 91.96%

--- Training with Activation: ELU, Optimizer: RMSprop ---
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/20] Train Loss: 4.2791, Train Acc: 39.84% | Val Loss: 0.7989, Val Acc: 82.61%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [2/20] Train Loss: 0.8349, Train Acc: 76.77% | Val Loss: 0.5516, Val Acc: 85.65%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [3/20] Train Loss: 0.4699, Train Acc: 86.79% | Val Loss: 0.2179, Val Acc: 93.48%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [4/20] Train Loss: 0.3179, Train Acc: 91.03% | Val Loss: 0.1569, Val Acc: 94.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [5/20] Train Loss: 0.2133, Train Acc: 93.26% | Val Loss: 0.0888, Val Acc: 98.26%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [6/20] Train Loss: 0.1677, Train Acc: 95.11% | Val Loss: 0.0848, Val Acc: 97.83%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [7/20] Train Loss: 0.1579, Train Acc: 95.43% | Val Loss: 0.1139, Val Acc: 97.17%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [8/20] Train Loss: 0.1427, Train Acc: 95.90% | Val Loss: 0.1192, Val Acc: 96.09%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [9/20] Train Loss: 0.1207, Train Acc: 96.74% | Val Loss: 0.0279, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/20] Train Loss: 0.1131, Train Acc: 96.98% | Val Loss: 0.0203, Val Acc: 99.57%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [11/20] Train Loss: 0.0930, Train Acc: 97.15% | Val Loss: 0.0233, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [12/20] Train Loss: 0.0831, Train Acc: 97.47% | Val Loss: 0.0511, Val Acc: 98.70%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [13/20] Train Loss: 0.0834, Train Acc: 97.55% | Val Loss: 0.0097, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [14/20] Train Loss: 0.0643, Train Acc: 97.91% | Val Loss: 0.0358, Val Acc: 98.70%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [15/20] Train Loss: 0.0788, Train Acc: 98.10% | Val Loss: 0.0123, Val Acc: 99.35%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [16/20] Train Loss: 0.0560, Train Acc: 98.10% | Val Loss: 0.0455, Val Acc: 98.26%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [17/20] Train Loss: 0.0704, Train Acc: 97.91% | Val Loss: 0.0235, Val Acc: 99.78%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [18/20] Train Loss: 0.0512, Train Acc: 98.51% | Val Loss: 0.0238, Val Acc: 99.13%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [19/20] Train Loss: 0.0596, Train Acc: 98.10% | Val Loss: 0.0323, Val Acc: 98.70%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                                                                       
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [20/20] Train Loss: 0.0611, Train Acc: 98.15% | Val Loss: 0.0020, Val Acc: 100.00%
Best Epoch: 20, Test Accuracy: 99.13%
</pre></div>
</div>
</div>
</div>
</section>
<section id="experiment-loop-training-and-tracking-results">
<h3><strong>Experiment Loop: Training and Tracking Results</strong><a class="headerlink" href="#experiment-loop-training-and-tracking-results" title="Link to this heading">#</a></h3>
<p>This is the core of our experiments. <strong>We loop through every combination of activation function and optimizer.</strong> For each run, we create a fresh CNN with the selected activation, set up the loss function, and initialize the optimizer.</p>
<p>Inside the epoch loop, we first train the model on the training set. We keep track of running loss and the number of correct predictions to calculate accuracy. After each epoch, we switch to evaluation mode and measure performance on the validation set. We store the losses and accuracies for both training and validation, so we can plot them later.</p>
<p>We also <strong>keep track of the best validation accuracy</strong> and which epoch achieved it. At the end of each experiment, we reload the best model weights and measure test accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot Loss/Accuracy Curves for All Experiments</span>
<span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">experiment_results</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;Val Loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Val Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss Curves: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;Activation&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;Optimizer&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;Train Acc&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Acc&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;Val Acc&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Val Acc&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy Curves: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;Activation&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;Optimizer&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy (%)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/dee3b9a42be0ee8893bac1575248a95f75646f25f0df8a21a319920b3ba48fb5.png" src="../_images/dee3b9a42be0ee8893bac1575248a95f75646f25f0df8a21a319920b3ba48fb5.png" />
<img alt="../_images/599083bf79b3d2a7d2a8208ea548425014a160b2bd705743c835f522f176a25a.png" src="../_images/599083bf79b3d2a7d2a8208ea548425014a160b2bd705743c835f522f176a25a.png" />
<img alt="../_images/88e2d5f04e254ffae99370f3f5e96ee5da8032e8ed59a1b679308d27404cf348.png" src="../_images/88e2d5f04e254ffae99370f3f5e96ee5da8032e8ed59a1b679308d27404cf348.png" />
<img alt="../_images/498f8abeb680829759e24554dfd7de360763adba39eb5ce109bc1e1f45cca392.png" src="../_images/498f8abeb680829759e24554dfd7de360763adba39eb5ce109bc1e1f45cca392.png" />
<img alt="../_images/539321e535bbc1df4a3cf8fd0fdf68900e2bce4c10f063f5f2f6ded6f5dec4cd.png" src="../_images/539321e535bbc1df4a3cf8fd0fdf68900e2bce4c10f063f5f2f6ded6f5dec4cd.png" />
<img alt="../_images/adcc2e7d7b7df1295cc7f936c48a9fc011340fce13a748ac33a8a17d544053ed.png" src="../_images/adcc2e7d7b7df1295cc7f936c48a9fc011340fce13a748ac33a8a17d544053ed.png" />
<img alt="../_images/6cd3682c05705c167e2fbd93f74bbbd14f753caf337bd7375ece0e9006a0dd40.png" src="../_images/6cd3682c05705c167e2fbd93f74bbbd14f753caf337bd7375ece0e9006a0dd40.png" />
<img alt="../_images/bb64e80fa4e23a1b2b34de4d672028780f2dd13d5b729bb97bdf0ecd8acf434e.png" src="../_images/bb64e80fa4e23a1b2b34de4d672028780f2dd13d5b729bb97bdf0ecd8acf434e.png" />
<img alt="../_images/f6075396565bf83823328f6c180d8f221a30bd611d0f49761976c15d86990c94.png" src="../_images/f6075396565bf83823328f6c180d8f221a30bd611d0f49761976c15d86990c94.png" />
</div>
</div>
</section>
</section>
<section id="key-takeaways">
<h2>Key Takeaways<a class="headerlink" href="#key-takeaways" title="Link to this heading">#</a></h2>
<section id="relu-activation-function">
<h3>ReLU Activation Function<a class="headerlink" href="#relu-activation-function" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Adam:</strong> The model converges quickly, with training and validation losses dropping sharply and stabilizing near zero around epochs 5â€“10. Accuracies rise rapidly, reaching approximately <strong>99.13%</strong> on the test set. Validation accuracy is slightly higher than training after epoch 2. Best epoch: <strong>9</strong>.</p></li>
<li><p><strong>RMSprop:</strong> Losses drop quickly, but a noticeable spike occurs in validation loss around epoch 12. Accuracies mirror this behavior, with validation accuracy dipping before stabilizing. Test accuracy is approximately <strong>99.78%</strong>. Best epoch: <strong>15</strong>.</p></li>
<li><p><strong>SGD:</strong> Convergence is slower. Losses decline steadily over 20 epochs. Test accuracy is approximately <strong>89.78%</strong>, indicating the model has not fully converged. Best epoch: <strong>20</strong>.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="leakyrelu-activation-function">
<h3>LeakyReLU Activation Function<a class="headerlink" href="#leakyrelu-activation-function" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Adam:</strong> Both losses drop sharply and stabilize near zero around epochs 5â€“10. Test accuracy reaches approximately <strong>99.57%</strong>. Best epoch: <strong>10</strong>.</p></li>
<li><p><strong>RMSprop:</strong> Losses drop sharply and stabilize near zero by epoch 5. Test accuracy reaches approximately <strong>99.35%</strong>. Best epoch: <strong>16</strong>.</p></li>
<li><p><strong>SGD:</strong> Convergence is slower. Test accuracy reaches approximately <strong>89.57%</strong>, indicating partial convergence. Best epoch: <strong>19</strong>.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="elu-activation-function">
<h3>ELU Activation Function<a class="headerlink" href="#elu-activation-function" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Adam:</strong> Losses drop sharply and stabilize near zero around epoch 5. Test accuracy reaches approximately <strong>98.04%</strong>. Best epoch: <strong>17</strong>.</p></li>
<li><p><strong>RMSprop:</strong> Losses decrease sharply from a high starting point and stabilize near zero by epoch 5. Test accuracy reaches <strong>99.13%</strong>. Best epoch: <strong>20</strong>.</p></li>
<li><p><strong>SGD:</strong> Convergence is slower. Test accuracy reaches approximately <strong>91.96%</strong>, indicating partial convergence. Best epoch: <strong>19</strong>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">heatmap_data</span> <span class="o">=</span> <span class="n">summary</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s1">&#39;Activation&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s1">&#39;Optimizer&#39;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="s1">&#39;Test Accuracy&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">heatmap_data</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.2f&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;YlGnBu&#39;</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Accuracy (%)&#39;</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Test Accuracy Heatmap&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d1f57a75488bddbedb485424831cffb8083b11140d9bc8515fb0b7c61a0ff1b7.png" src="../_images/d1f57a75488bddbedb485424831cffb8083b11140d9bc8515fb0b7c61a0ff1b7.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Summary Table</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">summary</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([{</span>
    <span class="s1">&#39;Activation&#39;</span><span class="p">:</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;Activation&#39;</span><span class="p">],</span>
    <span class="s1">&#39;Optimizer&#39;</span><span class="p">:</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;Optimizer&#39;</span><span class="p">],</span>
    <span class="s1">&#39;Best Epoch&#39;</span><span class="p">:</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;Best Epoch&#39;</span><span class="p">],</span>
    <span class="s1">&#39;Test Accuracy&#39;</span><span class="p">:</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;Test Accuracy&#39;</span><span class="p">]</span>
<span class="p">}</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">experiment_results</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ðŸ“Š Summary of All Experiments&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">summary</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;Test Accuracy&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ðŸ“Š Summary of All Experiments
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Activation</th>
      <th>Optimizer</th>
      <th>Best Epoch</th>
      <th>Test Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ReLU</td>
      <td>RMSprop</td>
      <td>15</td>
      <td>99.782609</td>
    </tr>
    <tr>
      <th>1</th>
      <td>LeakyReLU</td>
      <td>Adam</td>
      <td>10</td>
      <td>99.565217</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LeakyReLU</td>
      <td>RMSprop</td>
      <td>16</td>
      <td>99.347826</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ReLU</td>
      <td>Adam</td>
      <td>9</td>
      <td>99.130435</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ELU</td>
      <td>RMSprop</td>
      <td>20</td>
      <td>99.130435</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ELU</td>
      <td>Adam</td>
      <td>17</td>
      <td>98.043478</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ELU</td>
      <td>SGD</td>
      <td>19</td>
      <td>91.956522</td>
    </tr>
    <tr>
      <th>7</th>
      <td>ReLU</td>
      <td>SGD</td>
      <td>20</td>
      <td>89.782609</td>
    </tr>
    <tr>
      <th>8</th>
      <td>LeakyReLU</td>
      <td>SGD</td>
      <td>19</td>
      <td>89.565217</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>
<section id="conclusion">
<h2><strong>Conclusion</strong><a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>From this lab activity, several key insights emerged regarding the impact of activation functions and optimizers on the performance of convolutional neural networks. We observed that both the choice of activation function and optimizer significantly influence the convergence speed, stability, and final accuracy of the model. Specifically, <strong>ReLU and LeakyReLU</strong> combined with adaptive optimizers such as <strong>Adam and RMSprop</strong> achieved the highest test accuracies, <strong>consistently above 99%,</strong> while SGD generally lagged, showing slower convergence and lower final accuracy.</p>
<p>This task allowed us to practice designing systematic experiments where only select hyperparameters are varied while keeping all others constant. Through this approach, we were able to isolate the effect of activations and optimizers on model performance. The experiments also emphasized the importance of monitoring both training and validation metrics to detect issues such as overfitting, spikes in loss, or slow convergence.</p>
<p>Challenges included handling the variability of convergence across optimizer-activation combinations and understanding the subtle interactions between activation functions and gradient-based optimizers. It was also evident that some combinations, while achieving high training accuracy, could overfit, as indicated by discrepancies between training and validation metrics.</p>
<section id="bottomline">
<h3><strong>Bottomline:</strong><a class="headerlink" href="#bottomline" title="Link to this heading">#</a></h3>
<p>Looking back to the results we achieved, <strong>Adam</strong> and <strong>RMSprop</strong> are clearly the more reliable optimizers for this task, consistently achieving above 99 percent with <strong>ReLU</strong> or <strong>LeakyReLU.</strong> SGD is noticeably slower and less stable. For this dataset, simpler activations like ReLU and LeakyReLU edge out ELU slightly, especially when paired with adaptive optimizers. If we were to pick one combination for deployment or further experiments, ReLU + RMSprop or ReLU + Adam would be the safest bet, balancing fast convergence with top accuracy.</p>
<p>Overall, this activity reinforced our understanding of how hyperparameters shape learning dynamics. It trained us to interpret model behavior through quantitative metrics, visualize trends in loss and accuracy, and make informed decisions when tuning deep learning models. Beyond coding, it cultivated a mindset of experimentation, critical analysis, and methodical evaluation that will be crucial in future machine learning tasks.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./labs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="DL-Lab6.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Laboratory Task 6</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="Homework201.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>When Learning Rates Decay: What Really Happens Inside a CNN</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kein-jake-a-culanggo">Kein Jake A. Culanggo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ds4a">DS4A</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-source"><strong>Dataset Source:</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-class"><strong>Dataset Class</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-a-sample"><strong>Loading a Sample</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-we-did-it-this-way"><strong>Why We Did It This Way</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformations-getting-images-ready"><strong>Transformations: Getting Images Ready</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-and-splitting-the-dataset"><strong>Loading and Splitting the Dataset</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cnn-definition-flexible-activation-functions"><strong>CNN Definition: Flexible Activation Functions</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-setup-activations-optimizers-and-device"><strong>Experiment Setup: Activations, Optimizers, and Device</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-loop-training-and-tracking-results"><strong>Experiment Loop: Training and Tracking Results</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-takeaways">Key Takeaways</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relu-activation-function">ReLU Activation Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#leakyrelu-activation-function">LeakyReLU Activation Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#elu-activation-function">ELU Activation Function</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion"><strong>Conclusion</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bottomline"><strong>Bottomline:</strong></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Kein Jake Culanggo
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>