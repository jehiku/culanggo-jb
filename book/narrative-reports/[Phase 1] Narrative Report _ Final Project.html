<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>[Phase 1] Narrative Report _ Final Project</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        .page {
            margin-bottom: 30px;
            border: 1px solid #ddd;
            padding: 20px;
            background: white;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <h1>[Phase 1] Narrative Report _ Final Project</h1>
    <div class="page">
        <h2>Page 1</h2>
        <div> <br>
        Narrative Report | [Phase 1] Final Project​<br>
        By: Kein Jake A. Culanggo <br>
        This report documents the development of our project and outlines my individual contribution <br>
        to the team’s progress. The study began with collaborative brainstorming sessions between Ms. dela <br>
        Cruz and me, during which we explored several potential directions. I proposed the idea of developing <br>
        a deep learning system for American Sign Language recognition, which became the foundation for <br>
        our project title, Automated ASL Fingerspelling Recognition for Educational Platforms Using CNN <br>
        Frame Classification and Letter Sequence Reconstruction. This concept provided our team with a <br>
        coherent and socially relevant focus, positioning the project within a context that aligned with course <br>
        constraints. <br>
        As the team explored the approach, we recognized that training a model to process the entire <br>
        ASL lexicon was unrealistic. We refined the scope to fingerspelling through letters and numbers. This <br>
        allowed us to manage dataset requirements while maintaining relevance. I worked again with Ms. dela <br>
        Cruz to ensure that this narrowed scope did not diminish the purpose of the project. Together, we <br>
        anchored the direction toward supporting an ASL learning platform rather than attempting full <br>
        language translation. In addition to conceptual framing, I authored the Background of the Study <br>
        section, integrating literature on ASL learning and motor skill acquisition, which helped reinforce the <br>
        project’s applicability and educational merit. <br>
        Our current progress reflects ongoing development. The model still confuses several letters <br>
        with visually similar numbers. Initial testing showed inconsistencies with basic video samples, with <br>
        the classifier performing unreliably under variations in lighting, hand positioning, and recording <br>
        angles. The team has begun retaking sample videos to build a more consistent dataset for validation <br>
        and tuning, exploring measures to determine conditions for better performance. Several challenges <br>
        have emerged. The dataset lacks diversity in gesture style, increasing the risk of model overfitting. <br>
        Similarities between certain letter–number pairs reduce classification confidence, and insufficient <br>
        granularity in training examples has contributed to misclassification. Despite these issues, each <br>
        challenge guides deliberate preprocessing, dataset refinement, and model adjustment strategies. <br>
        Team contributions have been clear and complementary. Ms. dela Cruz demonstrated strong <br>
        initiative in advancing the technical portion, validating feasibility through trial programming <br>
        executions and overseeing testing. Mr. Dane Casino diligently prepared the Jupyter Book serving as <br>
        the organized repository of our documentation. Mr. Abainza fulfilled assigned tasks, though <br>
        communication was limited; coordination with him was primarily handled by Ms. dela Cruz. As part <br>
        of dataset preparation, the group recorded individual videos of hand signs corresponding to the letters <br>
        of our names. These samples enabled Ms. dela Cruz to begin real-world validation and fine-tuning of <br>
        the model. <br>
        Overall, the project progresses through iterative refinement. My contributions have centered <br>
        on conceptual structuring, academic framing, and supporting the team’s technical direction through a <br>
        coherent background and aligned use case. The next steps involve collecting cleaner, consistent <br>
        gesture recordings, strengthening preprocessing, adjusting hyperparameters, and preparing the <br>
        improved classifier for integration into the learning platform framework. Through coordinated effort <br>
        and continued experimentation, the team aims to move the model toward a stable and educationally <br>
        meaningful performance. <br>
        </div>
    </div>
</body>
</html>